# Oneshot Learning Networks

Another project we worked on this summer was create [oneshot learning] networks. Oneshot learning means that the network is fed a much smaller amount of training data to see how well it can learn from smaller chunks of data which is more realistic. The accuracies achieved using oneshot learning are usually pretty sporadic and tend to level off much lower. Furthermore, oneshot networks tend to be overfit. I wrote three oneshot networks for each data set that I was working with in order to compare the accuracies to the [LSH oneshot accuracies]. The toy problem network uses a validation set and goes back and chooses the best supports to determine the best support accuracy.

ADD MORE INFO ABOUT ONESHOT LEARNING

## Network

TO DO

## Data Sets

TO DO

## Use

TO DO

## Results

TO DO -- also link to google sheets and add graphs (maybe even link to the LSH page)

## Future Work 

TO DO

[oneshot learning]: https://en.wikipedia.org/wiki/One-shot_learning
[LSH oneshot accuracies]: https://github.com/slancas1/budapest_research/tree/master/LSH
